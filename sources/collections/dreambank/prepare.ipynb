{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25124441",
   "metadata": {},
   "source": [
    "## DreamBank\n",
    "\n",
    "Convert DreamBank's raw HTML files into tabular format.\n",
    "\n",
    "Processing steps for tabular export.\n",
    "\n",
    "* Remove non-english datasets\n",
    "* Parse dream number/ID and metadata from beginning of dream reports into their own columns\n",
    "* Parse dream word counts from end of dream reports into its own column\n",
    "* Parse dataset metadata into separate columns\n",
    "* Replace newlines with single spaces in brief descriptions of dataset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70b705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import os\n",
    "import re\n",
    "from requests.exceptions import HTTPError\n",
    "import tarfile\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pooch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3679a466",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97697cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a version of DreamBank HTML that has already been attached\n",
    "# to a GitHub release, use Pooch to download/cache that file and get the filename from there.\n",
    "# Otherwise it is assumed there is a new development version in `raw/` to work with.\n",
    "RAW_URL = \"https://github.com/remrama/dreambank/releases/download/v1.alpha2/dreambank.tar.xz\"\n",
    "RAW_HASH = \"md5:6ab629e9c13251d228db7ec1a93ffeb6\"\n",
    "try:\n",
    "    archive_fname = pooch.retrieve(RAW_URL, RAW_HASH)\n",
    "except HTTPError as e:\n",
    "    if str(e).startswith(\"404 Client Error: Not Found for url\"):\n",
    "        archive_fname = \"./raw/output/dreambank.tar.xz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da3076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping non-English dataset: german-f.de\n",
      "Dropping non-English dataset: german-m.de\n",
      "Dropping non-English dataset: vonuslar.de\n",
      "Dropping non-English dataset: zurich-f.de\n",
      "Dropping non-English dataset: zurich-m.de\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all the datasets available in the archive.\n",
    "datasets = []\n",
    "with tarfile.open(archive_fname, \"r:xz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        if member.isdir() and member.name != \".\":\n",
    "            datasets.append(os.path.basename(member.name))\n",
    "\n",
    "# Drop non-english datasets.\n",
    "for ds in datasets[:]:\n",
    "    if \".\" in ds:\n",
    "        datasets.remove(ds)\n",
    "        print(f\"Dropping non-English dataset: {ds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb980fef",
   "metadata": {},
   "source": [
    "## Define functions for HTML extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9b3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_content(dataset: str, component: str) -> bytes:\n",
    "    \"\"\"Extracts the info.html, dreams.html, or moreinfo.html content for a given dataset from the archive.\"\"\"\n",
    "    assert component in {\"dreams\", \"info\", \"moreinfo\"}, f\"Invalid component: {component}\"\n",
    "    fname = f\"./{dataset}/{component}.html\"\n",
    "    with tarfile.open(archive_fname, \"r:xz\") as tar:\n",
    "        with tar.extractfile(fname) as f:\n",
    "            content = f.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d60ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dreams_from_html(dataset: str) -> list[dict[str, str]]:\n",
    "    \"\"\"Parse DreamBank HTML dreams page for a given dataset.\n",
    "    \n",
    "    * Every dream starts with a #-padded number (e.g., #1) followed by a space.\n",
    "        It's not always just numbers. Sometimes it has letters (e.g., #111a) or dashes\n",
    "        (e.g., #B-055 in Jasmine's dreams; I think this is because it's in the Jasmine-all\n",
    "        dataset and the B-055 indicates it's from her \"B\" series).\n",
    "    * Dreams may optionally have a parenthetical between the number and the dream text.\n",
    "        This parenthetical may contain a date, title, age, or other information.\n",
    "        There is no standard format for what is in here and it will vary by dataset.\n",
    "        It's surrounding by single spaces. There might be parenthesis inside the parenthetical.\n",
    "    * The dream text follows.\n",
    "    * Every dream ends with a word count in parentheses (e.g., (123 words)).\n",
    "    * Every dream starts with a number sign (#) followed by the dream number in the whole sequence.\n",
    "        This is not necessarily a pure integer, as some dreams have letter suffixes (e.g., 111a).\n",
    "        This is not alway a full range of row numbers. E.g., HVdC datasets go up to 500, but\n",
    "        there are some missing dreams. The missing numbers are between 1-500.\n",
    "        Sometimes it has strings in it, e.g., #F21-5 in Peruvian dreams.\n",
    "        Sometimes it has sex and age in it, e.g., #89 (F, age 18) in West Coast dreams.\n",
    "        There are sometimes sup-parantheticals within the main parenthetical, but fortunatelly\n",
    "        they are always at the end of the main parenthetical (e.g., #1027 (2007-01-22 (15))),\n",
    "        which makes them easier to find.\n",
    "    * Dreams may optionally have a date in parentheses after the dream number.\n",
    "        The date, if present, can be in a variety of formats, sometimes separated by slashes or dashes.\n",
    "        Also a question mark is there sometimes to indicate uncertainty (e.g., 1985?).\n",
    "        There is sometimes another value in a sub-parenthetical within the date.\n",
    "        E.g., a number that I think represents age in Izzy's dreams (e.g., #1027 (2007-01-22 (15)),\n",
    "        or a period title in Madeline's dreams (e.g., #0771 (2003-19-12 (Post-Grad))).\n",
    "    * Some dreams have a title following the date, in brackets and quotes (e.g., [\"Outlaws Hiding\"]).\n",
    "        I've seen this in some Barb Sanders dreams.\n",
    "    * Barbara baseline always ends with [BL] at end of report.\n",
    "    \"\"\"\n",
    "    content = extract_file_content(dataset, \"dreams\")\n",
    "    soup = BeautifulSoup(content, \"html.parser\", from_encoding=\"ISO-8859-1\")\n",
    "    # Find all spans that do not have \"comment\" class labels.\n",
    "    # Comments will already be present in the regular spans/dreams as bracketed content.\n",
    "    dreams = []\n",
    "    dream_spans = soup.find_all(\"span\", style=False, class_=lambda x: x != \"comment\")\n",
    "    for span in dream_spans:\n",
    "        span_text = span.get_text(separator=\" \", strip=True)\n",
    "        # Extract the dream number (and potentially date) from beginning of string\n",
    "        # Sometimes dream number is a string, like 111a (e.g., Alta)\n",
    "        # Date is sometimes present if provided by dreamer\n",
    "        # Dream ID is always present and represents the number of the dream in the whole sequence\n",
    "        # PREFACE_PATTERN = r\"^#(?P<dream_id>\\S+) (?P<metadata>\\(.+?\\){1,2} )?\"\n",
    "        PREFACE_PATTERN = r\"^#(?P<dream_id>\\S+) (\\((?P<metadata>.{1,30}?)\\) )?\"\n",
    "        preface_match = re.match(PREFACE_PATTERN, span_text)\n",
    "        assert preface_match is not None, f\"Error parsing dream preface for dataset {dataset}, span text: {span_text}\"\n",
    "        # There is always _supposed_ to be a space bewteen last word and word count paranthetical,\n",
    "        # but this isn't always the case. Eg, alta #49, bay_area_girls_456 #219-11.\n",
    "        # It's always supposed to be a return line before the word count paranthetical,\n",
    "        # but looks like it is also a space sometimes, particularly when there is a bracketed\n",
    "        # statement right before it (e.g., [BL] (87 words)).\n",
    "        # So instead of a newline preceding, we will just look for any whitespace _optionally_.\n",
    "        PROLOGUE_PATTERN = r\"(\\s+)?\\((?P<word_count>[0-9]+) words\\)$\"\n",
    "        prologue_match = re.search(PROLOGUE_PATTERN, span_text)\n",
    "        # prologue_match = re.search(PROLOGUE_PATTERN, span_text)\n",
    "        assert prologue_match is not None, f\"Error parsing dream prologue for dataset {dataset}, span text: {span_text}\"\n",
    "        # n_wc_matches = len(re.findall(r\"[ \\n]?\\([0-9]+ words\\)$\", dream_and_wc_text))\n",
    "        \n",
    "        # Extract the id_match from the span text\n",
    "        # dream_n = match_.group(1)  # The number of dream in the whole sequence\n",
    "        # dream_date = match_.group(3)  # will be None if not found\n",
    "        # # Remove the dream number (and potentially date) from the beginning of string\n",
    "        # dream_and_wc_text = re.sub(r\"^#([0-9]+) ((\\(\\S*\\)) )?\", \"\", span_text)\n",
    "        # # Remove the word count from end of string\n",
    "        # n_wc_matches = len(re.findall(r\"[ \\n]?\\([0-9]+ words\\)$\", dream_and_wc_text))\n",
    "        # assert n_wc_matches == 1, f\"Found {n_wc_matches} WC match for dataset {dataset}, dream {dream_n} (expected 1).\"\n",
    "        # dream_text = re.sub(r\"[ \\n]?\\([0-9]+ words\\)$\", \"\", dream_and_wc_text)\n",
    "        # assert dream_n not in data, f\"Unexpected duplicate dream number: {dream_n} in dataset {dataset}.\"\n",
    "        \n",
    "        # Remove extracted preface and prologue from span text to get dream text\n",
    "        dreams.append(\n",
    "            {\n",
    "                \"dataset\": dataset,\n",
    "                \"dream_id\": preface_match.group(\"dream_id\"),\n",
    "                \"metadata\": pd.NA if preface_match.group(\"metadata\") is None else preface_match.group(\"metadata\"),\n",
    "                \"word_count\": int(prologue_match.group(\"word_count\")),\n",
    "                \"dream_text\": re.sub(PROLOGUE_PATTERN, \"\", re.sub(PREFACE_PATTERN, \"\", span_text)),\n",
    "            }\n",
    "        )\n",
    "    # Make sure the correct number of dreams were extracted.\n",
    "    # At the top of each page, DreamBank will say how many dreams are present in the\n",
    "    # total dataset, as well as how many are displayed on the page. These, and the total\n",
    "    # amount of dreams extracted, should all be the same.\n",
    "    n_dreams_statement = soup.find(\"h4\").find_next().get_text()\n",
    "    n_dreams_total, n_dreams_displayed = map(int, re.findall(r\"[0-9]+\", n_dreams_statement))\n",
    "    n_dreams_extracted = len(dreams)\n",
    "    assert n_dreams_total == n_dreams_displayed == n_dreams_extracted\n",
    "    return dreams\n",
    "\n",
    "\n",
    "def extract_info_from_html(dataset: str, process_description: bool = True) -> dict[str, str]:\n",
    "    \"\"\"Parse DreamBank HTML info page for a given dataset into a dictionary.\n",
    "\n",
    "    This is the little window that pops up if you hit \"MORE INFO\" on the dataset search page.\n",
    "    The free text is same as what is on the Grid page, but the structured fields are not there.\n",
    "    The structured fields are also present in moreinfo page.\n",
    "    ```\n",
    "    Dream series: Alta: a detailed dreamer\n",
    "    Number of dreams: 422\n",
    "    Year: 1985-1997\n",
    "    Sex of the dreamer(s): female\n",
    "\n",
    "    Alta is an adult woman who wrote down her dreams in the late 1980s and early 1990s, and added a few in 1997 when she called to offer the dreams to us. This series has not been heavily studied yet.\n",
    "    ```\n",
    "    * long_name (str): The dataset title.\n",
    "    * n_dreams (int): The total number of dreams in the dataset.\n",
    "    * timeframe (str): Provided year or timeframe of the dataset.\n",
    "    * sex (str): The provided sex of the dreamer.\n",
    "    * description (str): A long-form description of the dataset.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The more info (extended descriptions) are often very detailed with extensive HTML formatting.\n",
    "    So for now I'm leaving them out. Best way to view them honestly is just to go to the link.\n",
    "    And the link is the same for everyone so including the link in the dataset CSV is redundant.\n",
    "    But for now a half solution is to add a column that clarifies if there is more info available online.\n",
    "\n",
    "    Not every dataset has more info, but they all have a more info _page_. It just\n",
    "    might say no more info is available.\n",
    "\n",
    "    This is the little window that pops up whenever you hit \"click here\" in the initial\n",
    "    info page. I think it only applies to dream series??\n",
    "    The structured fields are duplicated here, but the free text from info is different than here.\n",
    "    That's like a brief description and this is a detailed thing, sometimes with extensive character\n",
    "    info and tables and stuff.\n",
    "    Not everyone has a direct link to this page, but if they have no more info and you go\n",
    "    directly to the link it will still have the structured fields, just say\n",
    "    \"Sorry, no additional info is available for this series.\"\n",
    "\n",
    "    \"\"\"\n",
    "    content = extract_file_content(dataset, \"info\")\n",
    "    soup = BeautifulSoup(content, \"html.parser\", from_encoding=\"ISO-8859-1\")\n",
    "    body = soup.find(\"body\")\n",
    "    long_name = body.find(string=\"Dream series:\").next.get_text(strip=True)\n",
    "    n_dreams = body.find(string=\"Number of dreams:\").next.get_text(strip=True)\n",
    "    timeframe = body.find(string=\"Year:\").next.get_text(strip=True)\n",
    "    sex = body.find(string=\"Sex of the dreamer(s):\").next.get_text(strip=True)\n",
    "    match_ = re.fullmatch(\n",
    "        r\"^.*Sex of the dreamer\\(s\\): (?:fe)?male\\n\\n\\n?(?P<description>.*?)\\s+(For the further analyses, click here.\\n)?\\[Back to search form\\]\\s+$\",\n",
    "        body.get_text(),\n",
    "        flags=re.DOTALL,\n",
    "    )\n",
    "    assert match_ is not None, f\"Error parsing info description for dataset {dataset}.\"\n",
    "    description = match_.group(\"description\")\n",
    "\n",
    "    # Just like the info page, we need to extract the description from the rest of the text.\n",
    "    # The search pattern is very similar, with just a slight difference in the trailing text.\n",
    "    content = extract_file_content(dataset, \"moreinfo\")\n",
    "    soup_ = BeautifulSoup(content, \"html.parser\", from_encoding=\"ISO-8859-1\")\n",
    "    body_ = soup_.find(\"body\")\n",
    "    long_name_ = body_.find(string=\"Dream series:\").next.get_text(strip=True)\n",
    "    n_dreams_ = body_.find(string=\"Number of dreams:\").next.get_text(strip=True)\n",
    "    timeframe_ = body_.find(string=\"Year:\").next.get_text(strip=True)\n",
    "    sex_ = body_.find(string=\"Sex of the dreamer(s):\").next.get_text(strip=True)\n",
    "    assert long_name == long_name_, f\"Mismatch in long_name for dataset {dataset}.\"\n",
    "    assert n_dreams == n_dreams_, f\"Mismatch in n_dreams for dataset {dataset}.\"\n",
    "    assert timeframe == timeframe_, f\"Mismatch in timeframe for dataset {dataset}.\"\n",
    "    assert sex == sex_, f\"Mismatch in sex for dataset {dataset}.\"\n",
    "    match__ = re.fullmatch(\n",
    "        r\"^.*Sex of the dreamer\\(s\\): (?:fe)?male\\n\\n\\n?(?P<extended_description>.*?)\\s+$\",\n",
    "        body_.get_text(),\n",
    "        flags=re.DOTALL,\n",
    "    )\n",
    "    assert match__ is not None, f\"Error parsing moreinfo for dataset {dataset}.\"\n",
    "    extended_description = match__.group(\"extended_description\")\n",
    "    extended_description_available = extended_description == \"Sorry, no additional info is available for this series.\"\n",
    "    # Could really just check for \"click here\" in the info description to see if more info is available.\n",
    "\n",
    "    if process_description:\n",
    "        # Clean up whitespace in description.\n",
    "        description = re.sub(r\"\\s+\", \" \", description)\n",
    "        # Optionally replace click here with markdown style link to url.\n",
    "        # url = f\"https://dreambank.net/more_info.cgi?further=1&series={dataset}\"\n",
    "    # Long names sometimes accidentatly have extra spaces too. I think it's just Izzy\n",
    "    # (e.g., \"Izzy,  age 14\"), but apply globally anyways.\n",
    "    long_name = re.sub(r\"\\s+\", \" \", long_name)\n",
    "    info = {\n",
    "        \"dataset\": dataset,\n",
    "        \"sex\": sex,\n",
    "        \"timeframe\": timeframe,\n",
    "        \"n_dreams\": int(n_dreams),\n",
    "        \"extended_description_available\": extended_description_available,\n",
    "        \"long_name\": long_name,\n",
    "        \"brief_description\": description,\n",
    "    }\n",
    "\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17546dca",
   "metadata": {},
   "source": [
    "## Process each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5622dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset west_coast_teens: 100%|████████████████| 89/89 [01:45<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_info = []\n",
    "extracted_dreams = []\n",
    "for dataset in (pbar := tqdm(datasets, ncols=90)):\n",
    "    pbar.set_description(f\"Processing dataset {dataset}\")\n",
    "    extracted_info.append(extract_info_from_html(dataset))\n",
    "    extracted_dreams.extend(extract_dreams_from_html(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c7b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.DataFrame.from_records(extracted_info)\n",
    "dreams = pd.DataFrame.from_records(extracted_dreams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a4b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will be a lot of duplicates because some dreams are subsets of others.\n",
    "# But there shouldn't be any duplicates within datasets.\n",
    "assert not dreams.duplicated().any()\n",
    "assert not dreams.duplicated(subset=[\"dataset\", \"dream_id\"]).any()\n",
    "assert not dreams.drop(columns=[\"metadata\"]).isna().any(axis=None)\n",
    "assert not datasets.isna().any(axis=None)\n",
    "assert not datasets.duplicated().any()\n",
    "assert datasets[\"dataset\"].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0d4f2",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b42aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"./output\"\n",
    "DATASETS_FNAME = \"datasets.csv.xz\"\n",
    "DREAMS_FNAME = \"dreams.csv.xz\"\n",
    "datasets_outpath = f\"{OUTDIR}/{DATASETS_FNAME}\"\n",
    "dreams_outpath = f\"{OUTDIR}/{DREAMS_FNAME}\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "TO_CSV_KWARGS = {\n",
    "    \"index\": False,\n",
    "    \"na_rep\": \"N/A\",\n",
    "    \"sep\": \",\",\n",
    "    \"mode\": \"x\",  # Switch to `w` to overwrite existing file\n",
    "    \"encoding\": \"utf-8-sig\",  # Include sig/BOM for better compatibility with Excel\n",
    "    \"compression\": \"xz\",\n",
    "    \"lineterminator\": \"\\n\",\n",
    "    \"quoting\": 2,  # 2 = csv.QUOTE_NONNUMERIC\n",
    "    \"quotechar\": '\"',\n",
    "    \"doublequote\": True,\n",
    "}\n",
    "datasets.to_csv(datasets_outpath, **TO_CSV_KWARGS)\n",
    "dreams.to_csv(dreams_outpath, **TO_CSV_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ea3b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: datasets.csv.xz\n",
      "size: 0.013464 MB\n",
      "md5: 1475582e2daa1da53920df50cb9fc98e\n",
      "sha256: 41ef784f267fe815ecf193b4e0a0902dfbc7d21488d68951bd0e04a5027ba408\n",
      "timestamp: 2025-12-29T22:33:10+00:00\n",
      "\n",
      "file: dreams.csv.xz\n",
      "size: 6.493452 MB\n",
      "md5: 2dcab92f9d9515df174388babb5c9e5a\n",
      "sha256: 17366792fcca7eca546660d30040bf49c1bb4139f04ac77fb50b1a67ade3c635\n",
      "timestamp: 2025-12-29T22:33:27+00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fn in [datasets_outpath, dreams_outpath]:\n",
    "    print(f\"file: {os.path.basename(fn)}\")\n",
    "    print(f\"size: {os.path.getsize(fn) / 1e6} MB\")\n",
    "    print(f\"md5: {pooch.file_hash(fn, alg='md5')}\")\n",
    "    print(f\"sha256: {pooch.file_hash(fn, alg='sha256')}\")\n",
    "    print(f\"timestamp: {datetime.fromtimestamp(os.path.getmtime(fn), tz=timezone.utc).isoformat(timespec='seconds')}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreambank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
